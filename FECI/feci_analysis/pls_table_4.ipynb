{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fff833c-6189-4ccd-9827-6597e82ec876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "\n",
    "\n",
    "def metacor(r, n, do_fisher=True, return_transformed=True, cor_type=\"pearson\", meta_type=\"fixed\"):\n",
    " if cor_type not in [\"pearson\", \"spearman\"]:\n",
    "  raise Exception(f\"Invalid correlation type \\\"{cor_type}\\\"\")\n",
    " if meta_type not in [\"fixed\", \"random\"]:\n",
    "  raise Exception(f\"Invalid meta analysis type \\\"{meta_type}\\\"\")\n",
    " if not do_fisher:\n",
    "  raise Exception(\"Non-Fisher's-z-transformed correlations not yet supported\")\n",
    " if meta_type == \"random\":\n",
    "  raise Exception(\"Random effects meta analysis not yet supported\")\n",
    " if not return_transformed:\n",
    "  raise Exception(\"Returning an untransformed common correlation coefficient estimate not yet supported\")\n",
    " do_override = False\n",
    " if do_fisher:\n",
    "  # Explicitly handle cases of r = 1 or r = -1\n",
    "  r_p_one = (r == 1.0).any(axis=1)\n",
    "  r_n_one = (r == -1.0).any(axis=1)\n",
    "  override = (r_p_one | r_n_one)\n",
    "  do_override = np.any(override)\n",
    "  if do_override:\n",
    "   # r_common = inf or -inf depending on sign of r\n",
    "   r_common_override_val = np.where(r_p_one, np.inf, np.where(r_n_one, -np.inf, np.nan))\n",
    "   # p = 0\n",
    "   p_override_val = np.where(override, 0.0, np.nan)\n",
    "   # Convert `override` to a column of a matrix, then broadcast to match `r`\n",
    "   # Needs to be done explicitly, as otherwise `where` could broadcast `override` along rows instead of columns\n",
    "   override_matrix = np.broadcast_to(np.reshape(override, (-1, 1)), r.shape)\n",
    "   r = np.where(override_matrix, np.nan, r)\n",
    "   n = np.where(override_matrix, np.nan, n)\n",
    "  r = np.arctanh(r)\n",
    " if cor_type == \"pearson\":\n",
    "  if do_fisher:\n",
    "   # Bonett (2000); DOI: 10.1007/BF02294183\n",
    "   variance = 1 / (n - 3)\n",
    "  else:\n",
    "   raise Exception(\"NYI\")\n",
    " elif cor_type == \"spearman\":\n",
    "  if do_fisher:\n",
    "   # Bonett (2000); DOI: 10.1007/BF02294183\n",
    "   variance = (1 + (np.square(r) / 2)) / (n - 3)\n",
    "  else:\n",
    "   raise Exception(\"NYI\")\n",
    " # Cooper (2009); ISBN: 978-0-87154-163-5\n",
    " weight = 1 / variance\n",
    " variance_common = 1 / np.nansum(weight, axis=1)\n",
    " r_common = np.nansum(np.multiply(weight, r), axis=1) * variance_common\n",
    " stddev_common = np.sqrt(variance_common)\n",
    " z = r_common / stddev_common\n",
    " p = 2 * scipy.stats.norm.sf(np.abs(z))\n",
    " if do_override:\n",
    "  r_common = np.where(override, r_common_override_val, r_common)\n",
    "  p = np.where(override, p_override_val, p)  \n",
    " return r_common, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "457e1eb4-e215-4915-98ac-c82d46c2983d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/th/svqqpgsj0xv3nvdlv74m8ky80000gn/T/ipykernel_9953/2434685194.py:44: RuntimeWarning: divide by zero encountered in divide\n",
      "  variance = (1 + (np.square(r) / 2)) / (n - 3)\n",
      "/var/folders/th/svqqpgsj0xv3nvdlv74m8ky80000gn/T/ipykernel_9953/2434685194.py:49: RuntimeWarning: divide by zero encountered in divide\n",
      "  variance_common = 1 / np.nansum(weight, axis=1)\n",
      "/var/folders/th/svqqpgsj0xv3nvdlv74m8ky80000gn/T/ipykernel_9953/2434685194.py:50: RuntimeWarning: invalid value encountered in multiply\n",
      "  r_common = np.nansum(np.multiply(weight, r), axis=1) * variance_common\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved FDR feci_fdr_table.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "\n",
    "# Load CSVs\n",
    "vecpac = pd.read_csv(\"updated_metabolite_pairs/COMBINATIONS_feci_VECPAC.csv\")\n",
    "lps    = pd.read_csv(\"updated_metabolite_pairs/COMBINATIONS_feci_LPS.csv\")\n",
    "dss    = pd.read_csv(\"updated_metabolite_pairs/COMBINATIONS_feci_DSS.csv\")\n",
    "\n",
    "# Rename correlation & p-value columns\n",
    "\n",
    "vecpac.columns.values[2] = 'VECPAC r'\n",
    "vecpac.columns.values[3] = 'VECPAC p-values'\n",
    "vecpac.columns.values[4] = \"VECPAC_n\"\n",
    "lps.columns.values[2]    = 'LPS r'\n",
    "lps.columns.values[3]    = 'LPS p-values'\n",
    "lps.columns.values[4] = \"LPS_n\"\n",
    "dss.columns.values[2]    = 'DSS r'\n",
    "dss.columns.values[3]    = 'DSS p-values'\n",
    "dss.columns.values[4] = \"DSS_n\"\n",
    "\n",
    "\n",
    "# Select only DSS r/p-values and LPS r/p-values\n",
    "dss_subset = dss[['DSS r', 'DSS p-values', \"DSS_n\"]]\n",
    "lps_subset = lps[['LPS r', 'LPS p-values', 'LPS_n']]\n",
    "\n",
    "#df = vecpac.merge(dss, on=[\"Metabolite 1\", \"Metabolite 2\"], how=\"right\")\n",
    "#df = df.merge(lps, on=[\"Metabolite 1\", \"Metabolite 2\"], how=\"right\")\n",
    "\n",
    "\n",
    "# Concatenate columns\n",
    "df = pd.concat([vecpac, dss_subset, lps_subset], axis=1)\n",
    "#df = pd.concat([vecpac, dss, lps], axis=1)\n",
    "\n",
    "#df = (\n",
    "    #vecpac\n",
    "    #.merge(dss, left_index=False, right_index=False, left_on=[\"Metabolite 1\", \"Metabolite 2\"], right_on=[\"Metabolite 1\", \"Metabolite 2\"], how=\"outer\")\n",
    "    #.merge(lps, on=[\"Metabolite 1\", \"Metabolite 2\"], how=\"outer\")\n",
    "#)\n",
    "\n",
    "# Add a new column based on sign consistency\n",
    "df['Consistent?'] = (\n",
    "    ((df['VECPAC r'] > 0) & (df['LPS r'] > 0) & (df['DSS r'] > 0)) |\n",
    "    ((df['VECPAC r'] < 0) & (df['LPS r'] < 0) & (df['DSS r'] < 0))\n",
    ")\n",
    "\n",
    "to_check = [\"VECPAC r\", \"LPS r\", \"DSS r\"]\n",
    "\n",
    "#i give up on coming up with a cleverer solution ngl\n",
    "\n",
    "df['r_values_count'] = df[to_check].notna().sum(axis=1)\n",
    "\n",
    "df[\"Meta-analysis_validity\"] = ((df[to_check].notna().sum(axis=1) >= 2) &\n",
    "    (np.sign(df[to_check]).sum(axis=1).abs() == df[to_check].notna().sum(axis=1))\n",
    ")\n",
    "    \n",
    "\n",
    "# Filter rows where Consistent? == True\n",
    "is_valid = df[\"Meta-analysis_validity\"]\n",
    "df_valid = df.loc[is_valid].copy()\n",
    "\n",
    "# get the correlation coefficients and respective array sizes for metacor\n",
    "r = df_valid[['VECPAC r', 'DSS r', 'LPS r']].to_numpy()\n",
    "n = df_valid[['VECPAC_n', 'DSS_n', 'LPS_n']].to_numpy()\n",
    "\n",
    "# Run meta-analysis\n",
    "r_common, p_values = metacor(r, n, do_fisher=True, cor_type=\"spearman\", meta_type=\"fixed\")\n",
    "\n",
    "# Add raw p-values column only to consistent metabolites\n",
    "df_valid['Meta-Analysis p-value'] = p_values\n",
    "# Add meta-analysis values into original table\n",
    "df['Meta-Analysis p-value'] = np.nan\n",
    "df.loc[is_valid, 'Meta-Analysis p-value'] = p_values\n",
    "\n",
    "# Run FDR correction only on valid p-values\n",
    "is_valid = ~df['Meta-Analysis p-value'].isna()\n",
    "rejected, pvals_corrected = fdrcorrection(df.loc[is_valid, 'Meta-Analysis p-value'], alpha=0.05, method='indep',is_sorted=False)\n",
    "\n",
    "# Add FDR results\n",
    "df['FDR'] = np.nan\n",
    "df.loc[is_valid, 'FDR'] = pvals_corrected\n",
    "df = df.drop('r_values_count', axis =1)\n",
    "\n",
    "# Save final file with meta-analysis and FDR correction\n",
    "fdr_file = \"feci_fdr_table.csv\"\n",
    "df.to_csv(fdr_file, index=False)\n",
    "print(\"Saved FDR\", fdr_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d789862-161e-4323-a561-739dfae20d40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6700ad-7b69-45ad-9579-d7164eda2fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
